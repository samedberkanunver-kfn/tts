ğŸ“„ Kokoro-82M TÃ¼rkÃ§e Fine-Tuning PlanÄ± (Claude Code iÃ§in teknik aÃ§Ä±klama)

AmaÃ§:
Kokoro-82M adlÄ± aÃ§Ä±k kaynak TTS modelini TÃ¼rkÃ§e konuÅŸacak hale getirmek. Model Hugging Faceâ€™ten alÄ±nacak (hexgrad/Kokoro-82M) ve Turkish_Speech_Corpus veri seti ile MacBook Pro M4 cihazda fine-tune edilecek. EÄŸitim dÃ¼ÅŸÃ¼k kaynaklÄ± olduÄŸundan LoRA tekniÄŸi kullanÄ±lacak.

1. Ortam Bilgisi

DonanÄ±m: MacBook Pro M4 (Apple Silicon)

Python 3.10

EÄŸitim frameworkâ€™Ã¼: PyTorch + torchaudio

Destek kitaplÄ±klar: Hugging Face datasets, loralib, sentencepiece, soundfile, librosa, einops

2. Model Bilgisi

Kokoro-82M aslÄ±nda StyleTTS2 mimarisine dayanan bir TTS modelidir (Bark tabanlÄ± DEÄÄ°LDÄ°R).

Hugging Face'de hexgrad/Kokoro-82M adresinde yer alÄ±r.

Tam fine-tune yerine LoRA ile hafif fine-tune yapÄ±lacaktÄ±r (parametre azaltmak iÃ§in).

EÄŸitim sÄ±rasÄ±nda yalnÄ±zca transformer katmanlarÄ± aÃ§Ä±lacak, diÄŸer tÃ¼m katmanlar sabit kalacaktÄ±r.

3. Veri Seti Bilgisi

Dataset: zeynepgulhan/mediaspeech-with-cv-tr (Hugging Face datasets Ã¼zerinden Ã§ekilecek)

Veri biÃ§imi: WAV dosyasÄ± (24kHz mono) + TÃ¼rkÃ§e transkript

Filtreleme: Ã‡ok kÄ±sa cÃ¼mleler (5 kelime altÄ±) Ã§Ä±karÄ±lacak

Gerekirse tÃ¼m WAV dosyalarÄ± yeniden 24kHz'e resample edilecek

4. EÄŸitim Ã–ncesi AdÄ±mlar

WAV dosyalarÄ± normalize edilecek (mono, 24kHz)

Dataset torch.utils.data.Dataset formatÄ±na Ã§evrilecek

text + audio ikilisiyle Ã¶rnekler oluÅŸturulacak

Tokenizer gerekiyorsa sentencepiece veya Kokoro ile gelen tokenizer kullanÄ±lacak

5. LoRA Entegrasyonu

TÃ¼m model parametreleri requires_grad=False olarak ayarlanacak

Sadece Linear katmanlar iÃ§indeki lora alt modÃ¼lleri eÄŸitilebilir hale getirilecek

LoRA parametreleri: r=8, alpha=16

LoRA, Hugging Face PEFT kÃ¼tÃ¼phanesi ile uygulanacak (loralib yerine)

6. EÄŸitim AyarlarÄ±

Optimizer: AdamW

Learning rate: 1e-4

Epochs: 5

Batch size: 1â€“2

Mixed precision (fp16): Apple MPS destekliyorsa aktif edilebilir

Loss function: MSELoss veya L1 loss (Ã¶rneÄŸin spectrogram hedefli)

Veriler kÃ¼Ã§Ã¼kse (1000â€“3000 Ã¶rnek), overfit riskine karÅŸÄ± erken durdurma yapÄ±lmalÄ±

7. Inference/Test

EÄŸitim sonunda model .generate(text) fonksiyonu ile test edilecek

Ã‡Ä±ktÄ± audio torchaudio ile .wav olarak kaydedilecek

Basit Ã¶rnek: "merhaba, size nasÄ±l yardÄ±mcÄ± olabilirim?"

8. Alternatif DonanÄ±m (Opsiyonel)

EÄŸitim sÃ¼resi M4 cihazda 6â€“12 saat sÃ¼rebilir

Daha hÄ±zlÄ± eÄŸitim iÃ§in AWS g4dn.xlarge veya g5.xlarge gibi GPUâ€™lu instanceâ€™lar Ã¶nerilir

Bu plana uygun olarak Claude Codeâ€™dan aÅŸaÄŸÄ±daki gibi ÅŸeyler yazmasÄ± istenebilir:

LoRA entegre edilmiÅŸ KokoroModel sÄ±nÄ±fÄ± sarmalayÄ±cÄ±

Turkish_Speech_Corpus veri Ã§ekme ve WAV iÅŸlemleri

torch.utils.data.Dataset sÄ±nÄ±fÄ±

EÄŸitim dÃ¶ngÃ¼sÃ¼ (train() fonksiyonu)

Model checkpoint kaydÄ±

generate() fonksiyonu ile inference Ã§Ä±ktÄ±sÄ±