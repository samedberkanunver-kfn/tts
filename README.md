# Turkish StyleTTS2 Fine-Tuning Pipeline

TÃ¼rkÃ§e metin-seslendirilmesi (TTS) iÃ§in StyleTTS2 modelinin LoRA ile fine-tune edilmesi.

## ğŸ¯ Proje Ã–zeti

Bu proje, StyleTTS2 mimarisini temel alan bir TTS modelini TÃ¼rkÃ§e konuÅŸacak hale getirmek iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r. DÃ¼ÅŸÃ¼k kaynaklÄ± eÄŸitim iÃ§in **PEFT LoRA** tekniÄŸi kullanÄ±lmakta ve **Apple Silicon (MPS)** cihazlarda Ã§alÄ±ÅŸacak ÅŸekilde optimize edilmiÅŸtir.

### Ã–zellikler

- âœ… StyleTTS2 tabanlÄ± TTS modeli (basitleÅŸtirilmiÅŸ implementasyon)
- âœ… PEFT LoRA ile parametre-verimli fine-tuning
- âœ… Apple Silicon (M1/M2/M3/M4) MPS desteÄŸi
- âœ… TÃ¼rkÃ§e phonemization (espeak-ng)
- âœ… Automatic dataset loading (Hugging Face datasets)
- âœ… Mixed precision (FP16) eÄŸitim
- âœ… TensorBoard logging
- âœ… Checkpoint yÃ¶netimi ve early stopping
- âœ… Batch inference ve WAV export

### Teknik Detaylar

- **Model**: SimplifiedStyleTTS2 (Text Encoder + Acoustic Model)
- **Dataset**: [zeynepgulhan/mediaspeech-with-cv-tr](https://huggingface.co/datasets/zeynepgulhan/mediaspeech-with-cv-tr) (48,781 samples)
- **Phonemizer**: espeak-ng (TÃ¼rkÃ§e G2P)
- **Sample Rate**: 24kHz
- **LoRA Config**: r=8, alpha=16, dropout=0.1
- **Training**: AdamW optimizer, L1/MSE loss, gradient accumulation

---

## ğŸ“‹ Gereksinimler

### Sistem Gereksinimleri

- **OS**: macOS (Apple Silicon Ã¶nerilen), Linux, Windows
- **RAM**: Minimum 16GB (eÄŸitim iÃ§in)
- **Disk**: ~5GB (dataset + checkpoints)
- **Python**: 3.8+

### DonanÄ±m

- **EÄŸitim**: MacBook Pro M4 veya Ã¼zeri (6-14 gÃ¼n)
- **Alternatif**: NVIDIA GPU (Tesla T4, RTX 3090, vb.) - daha hÄ±zlÄ± eÄŸitim

---

## ğŸš€ Kurulum

### 1. Repository'yi KlonlayÄ±n

```bash
cd /Users/kafein/Desktop/samed/tts
```

### 2. Python OrtamÄ± OluÅŸturun

```bash
# Python virtual environment
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate  # Windows
```

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
# PyTorch (Apple Silicon iÃ§in)
pip install torch torchvision torchaudio

# DiÄŸer baÄŸÄ±mlÄ±lÄ±klar
pip install -r requirements.txt
```

### 4. espeak-ng Kurulumu

**macOS:**
```bash
brew install espeak-ng
```

**Linux:**
```bash
sudo apt-get install espeak-ng
```

**Windows:**
[espeak-ng releases](https://github.com/espeak-ng/espeak-ng/releases) sayfasÄ±ndan indirin.

### 5. Kurulumu Test Edin

```bash
# Phonemizer test
python -m src.phonemizer

# Dataset test
python -m src.dataset
```

---

## ğŸ“š KullanÄ±m

### EÄŸitim (Training)

#### HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# Tam eÄŸitim (48k samples, ~100 epoch)
python -m src.train --config config.yaml

# Debug modunda (100 sample ile test)
python -m src.train --config config.yaml --limit-samples 100
```

#### Checkpoint'ten Devam Etme

```bash
python -m src.train --config config.yaml --resume checkpoints/checkpoint_step_5000.pt
```

#### EÄŸitim Parametreleri

`config.yaml` dosyasÄ±nda eÄŸitim parametrelerini dÃ¼zenleyebilirsiniz:

```yaml
training:
  batch_size: 2                      # Batch size (M4 iÃ§in 2 Ã¶nerilen)
  gradient_accumulation_steps: 16    # Effective batch: 2 Ã— 16 = 32
  learning_rate: 1.0e-4              # Learning rate
  num_epochs: 100                    # Epoch sayÄ±sÄ±
  device: "mps"                      # Device (mps, cuda, cpu)
  mixed_precision: true              # FP16 kullan
  early_stopping: true               # Early stopping aktif
  patience: 10                       # Early stopping patience
```

#### TensorBoard ile Ä°zleme

```bash
# EÄŸitim sÄ±rasÄ±nda baÅŸka bir terminalde:
tensorboard --logdir runs/

# TarayÄ±cÄ±da aÃ§Ä±n: http://localhost:6006
```

### Inference (Ses Ãœretimi)

#### Tek Metin

```bash
python -m src.inference \
  --checkpoint checkpoints/best_model.pt \
  --text "Merhaba, size nasÄ±l yardÄ±mcÄ± olabilirim?"
```

#### Toplu Ä°ÅŸlem (Batch)

```bash
# texts.txt dosyasÄ± oluÅŸturun (her satÄ±rda bir cÃ¼mle)
echo "Merhaba dÃ¼nya" >> texts.txt
echo "BugÃ¼n hava Ã§ok gÃ¼zel" >> texts.txt
echo "TÃ¼rkÃ§e metin seslendirilmesi" >> texts.txt

# Batch inference
python -m src.inference \
  --checkpoint checkpoints/best_model.pt \
  --input texts.txt \
  --output outputs/
```

#### Python API KullanÄ±mÄ±

```python
from src.inference import TTS
import yaml

# Config yÃ¼kle
with open('config.yaml') as f:
    config = yaml.safe_load(f)

# TTS sistemi oluÅŸtur
tts = TTS(
    config=config,
    checkpoint_path='checkpoints/best_model.pt'
)

# Ses Ã¼ret
audio = tts.generate("Merhaba, nasÄ±lsÄ±nÄ±z?")

# Kaydet
tts.save_audio(audio, "output.wav")
```

---

## ğŸ“ Proje YapÄ±sÄ±

```
tts/
â”œâ”€â”€ README.md              # Bu dosya
â”œâ”€â”€ plan.md                # Teknik plan (gÃ¼ncellenmiÅŸ)
â”œâ”€â”€ config.yaml            # EÄŸitim konfigÃ¼rasyonu
â”œâ”€â”€ requirements.txt       # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚
â”œâ”€â”€ src/                   # Kaynak kod
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ phonemizer.py      # TÃ¼rkÃ§e phonemization
â”‚   â”œâ”€â”€ dataset.py         # Dataset loading ve preprocessing
â”‚   â”œâ”€â”€ model.py           # StyleTTS2 + LoRA modeli
â”‚   â”œâ”€â”€ train.py           # EÄŸitim scripti
â”‚   â””â”€â”€ inference.py       # Inference scripti
â”‚
â”œâ”€â”€ data/                  # Veri dizini
â”‚   â”œâ”€â”€ cache/             # Hugging Face cache
â”‚   â””â”€â”€ phoneme_vocab.json # Phoneme vocabulary
â”‚
â”œâ”€â”€ checkpoints/           # Model checkpoints
â”‚   â”œâ”€â”€ lora/              # LoRA weights
â”‚   â”œâ”€â”€ best_model.pt      # En iyi model
â”‚   â””â”€â”€ checkpoint_*.pt    # DiÄŸer checkpoints
â”‚
â”œâ”€â”€ outputs/               # Ãœretilen ses dosyalarÄ±
â”‚   â””â”€â”€ output_*.wav
â”‚
â””â”€â”€ runs/                  # TensorBoard logs
```

---

## âš™ï¸ KonfigÃ¼rasyon

### Ana Parametreler

| Parametre | AÃ§Ä±klama | VarsayÄ±lan |
|-----------|----------|------------|
| `data.sample_rate` | Audio sample rate | 24000 |
| `data.n_mels` | Mel-spectrogram bins | 80 |
| `lora.r` | LoRA rank | 8 |
| `lora.lora_alpha` | LoRA alpha | 16 |
| `training.batch_size` | Batch size | 2 |
| `training.learning_rate` | Learning rate | 1e-4 |
| `training.num_epochs` | Epoch sayÄ±sÄ± | 100 |

### LoRA Hedef ModÃ¼ller

```yaml
lora:
  target_modules:
    - "q_proj"    # Query projection
    - "v_proj"    # Value projection
    - "k_proj"    # Key projection
    - "o_proj"    # Output projection
```

---

## ğŸ”§ Troubleshooting

### 1. espeak-ng BulunamadÄ±

**Hata:**
```
Failed to initialize espeak-ng backend
```

**Ã‡Ã¶zÃ¼m:**
```bash
# macOS
brew install espeak-ng

# Linux
sudo apt-get install espeak-ng

# Test
espeak-ng --version
```

### 2. MPS Out of Memory

**Hata:**
```
RuntimeError: MPS backend out of memory
```

**Ã‡Ã¶zÃ¼m:**
- `batch_size` deÄŸerini azaltÄ±n (2 â†’ 1)
- `gradient_accumulation_steps` deÄŸerini artÄ±rÄ±n
- `mixed_precision: false` yapÄ±n

```yaml
training:
  batch_size: 1
  gradient_accumulation_steps: 32
  mixed_precision: false
```

### 3. Dataset Format HatasÄ±

**Hata:**
```
WebDataset format error
```

**Ã‡Ã¶zÃ¼m:**
Dataset baÅŸarÄ±yla yÃ¼kleniyorsa sorun yok. Aksi takdirde:
```python
# Manuel yÃ¼kleme
from datasets import load_dataset
dataset = load_dataset("zeynepgulhan/mediaspeech-with-cv-tr", split="train")
```

### 4. YavaÅŸ EÄŸitim

**Ã–neriler:**
- GPU kullanÄ±n (AWS, Google Colab, vb.)
- Dataset boyutunu azaltÄ±n (`limit_samples` parametresi)
- Epoch sayÄ±sÄ±nÄ± azaltÄ±n
- Batch size artÄ±rÄ±n (GPU varsa)

---

## ğŸ“Š Beklenen Performans

### EÄŸitim SÃ¼resi (MacBook Pro M4)

| KonfigÃ¼rasyon | SÃ¼re |
|---------------|------|
| 100 samples (debug) | ~10 dakika |
| 1000 samples | ~2 saat |
| 10,000 samples | ~1 gÃ¼n |
| 48,000 samples (full) | ~7-14 gÃ¼n |

### GPU ile KarÅŸÄ±laÅŸtÄ±rma

| DonanÄ±m | SÃ¼re (48k samples, 100 epoch) |
|---------|-------------------------------|
| M4 (MPS) | 7-14 gÃ¼n |
| NVIDIA T4 | 3-5 gÃ¼n |
| NVIDIA RTX 3090 | 2-3 gÃ¼n |
| NVIDIA A100 | 1-2 gÃ¼n |

---

## âš ï¸ Ã–nemli Notlar

### 1. BasitleÅŸtirilmiÅŸ Implementasyon

Bu projede kullanÄ±lan **SimplifiedStyleTTS2** modeli, eÄŸitim amaÃ§lÄ± basitleÅŸtirilmiÅŸ bir versiyondur. Ãœretim kalitesi iÃ§in:

- [StyleTTS2 GitHub](https://github.com/yl4579/StyleTTS2) reposunu kullanÄ±n
- Bu projedeki LoRA wrapper'Ä± resmi model ile kullanÄ±n
- Diffusion ve style encoder bileÅŸenlerini ekleyin

### 2. Vocoder

Bu implementasyon **Griffin-Lim** vocoder kullanÄ±r (dÃ¼ÅŸÃ¼k kalite). Daha iyi sonuÃ§lar iÃ§in:

- [HiFi-GAN](https://github.com/jik876/hifi-gan) kullanÄ±n
- [Vocoder modelleri](https://huggingface.co/models?search=vocoder) indirin
- `inference.py`'de vocoder parametresini gÃ¼ncelleyin

### 3. Dataset Kalitesi

`mediaspeech-with-cv-tr` dataset'i Ã§eÅŸitli hoparlÃ¶rler iÃ§erir. Daha iyi sonuÃ§lar iÃ§in:

- Tek hoparlÃ¶r veri seti kullanÄ±n
- Veri filtrelemeyi iyileÅŸtirin
- Daha fazla eÄŸitim verisi ekleyin

---

## ğŸ“– Referanslar

### Makaleler

- [StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models](https://arxiv.org/abs/2306.07691)
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- [PEFT: Parameter-Efficient Fine-Tuning](https://huggingface.co/docs/peft)

### Kaynaklar

- **StyleTTS2 GitHub**: https://github.com/yl4579/StyleTTS2
- **Hugging Face PEFT**: https://github.com/huggingface/peft
- **Dataset**: https://huggingface.co/datasets/zeynepgulhan/mediaspeech-with-cv-tr
- **espeak-ng**: https://github.com/espeak-ng/espeak-ng

---

## ğŸ¤ KatkÄ±da Bulunma

Bu proje Claude Code tarafÄ±ndan oluÅŸturulmuÅŸtur ve eÄŸitim amaÃ§lÄ±dÄ±r. KatkÄ±larÄ±nÄ±zÄ± bekliyoruz:

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

---

## ğŸ“„ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r ve MIT LisansÄ± altÄ±nda daÄŸÄ±tÄ±lmaktadÄ±r.

**NOT**: Bu proje ÅŸu bileÅŸenleri kullanÄ±r:
- StyleTTS2 (MIT License)
- PEFT (Apache 2.0)
- PyTorch (BSD License)
- Hugging Face datasets (Apache 2.0)

---

## ğŸ‘¨â€ğŸ’» Yazar

**Claude Code** tarafÄ±ndan oluÅŸturuldu
- Plan: [plan.md](plan.md)
- Tarih: 2025

---

## ğŸ“ SonuÃ§

Bu proje, TÃ¼rkÃ§e TTS modeli eÄŸitmek iÃ§in eksiksiz bir pipeline saÄŸlar. **LoRA** ile dÃ¼ÅŸÃ¼k kaynaklÄ± eÄŸitim mÃ¼mkÃ¼ndÃ¼r ve **Apple Silicon** cihazlarda Ã§alÄ±ÅŸacak ÅŸekilde optimize edilmiÅŸtir.

BaÅŸarÄ±lÄ± eÄŸitimler! ğŸš€

---

## ğŸ“ Destek

SorularÄ±nÄ±z iÃ§in:
1. GitHub Issues aÃ§Ä±n
2. Config dosyalarÄ±nÄ±zÄ± kontrol edin
3. TensorBoard loglarÄ±nÄ± inceleyin
4. Troubleshooting bÃ¶lÃ¼mÃ¼ne bakÄ±n

**Happy TTS training!** ğŸ¤
