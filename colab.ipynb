{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish TTS Fine-Tuning on Google Colab\n",
    "\n",
    "Bu notebook, Kokoro-82M modelini TÃ¼rkÃ§e iÃ§in fine-tune etmek Ã¼zere hazÄ±rlanmÄ±ÅŸtÄ±r.\n",
    "\n",
    "**Gereksinimler:**\n",
    "- Runtime: GPU (T4 Ã¶nerilen)\n",
    "- RAM: High-RAM runtime (opsiyonel ama Ã¶nerilen)\n",
    "- Google Drive: Checkpoints kaydetmek iÃ§in\n",
    "\n",
    "**Tahmini SÃ¼re:**\n",
    "- Debug (100 sample): ~10 dakika\n",
    "- Full training (48k sample): 2-3 gÃ¼n (T4 GPU ile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU KontrolÃ¼ ve Runtime AyarlarÄ±\n",
    "\n",
    "âš ï¸ **Ã–NEMLI**: Runtime > Change runtime type > GPU (T4) seÃ§ili olmalÄ±!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU kontrolÃ¼\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Drive BaÄŸlantÄ±sÄ±\n",
    "\n",
    "Checkpoints ve TensorBoard loglarÄ± Drive'a kaydedilecek (session sonlanÄ±rsa kaybolmaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Checkpoint dizinleri oluÅŸtur\n",
    "!mkdir -p /content/drive/MyDrive/tts_checkpoints\n",
    "!mkdir -p /content/drive/MyDrive/tts_runs\n",
    "!mkdir -p /content/drive/MyDrive/tts_outputs\n",
    "\n",
    "print(\"\\nâœ“ Google Drive mounted successfully!\")\n",
    "print(\"  Checkpoints: /content/drive/MyDrive/tts_checkpoints\")\n",
    "print(\"  TensorBoard: /content/drive/MyDrive/tts_runs\")\n",
    "print(\"  Outputs: /content/drive/MyDrive/tts_outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Projeyi GitHub'dan Klonla\n",
    "\n",
    "**SeÃ§enek A**: GitHub kullanÄ±yorsanÄ±z (Ã¶nerilen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub'dan klonla\n",
    "import os\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/samedberkanunver-kfn/tts.git\"  # Buraya kendi repo URL'nizi yazÄ±n\n",
    "\n",
    "if os.path.exists('/content/tts'):\n",
    "    print(\"Removing old directory...\")\n",
    "    !rm -rf /content/tts\n",
    "\n",
    "!git clone {GITHUB_REPO} /content/tts\n",
    "%cd /content/tts\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SeÃ§enek B**: Google Drive'dan kopyala (GitHub kullanmÄ±yorsanÄ±z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive'dan kopyala (SeÃ§enek B)\n",
    "# Ã–nce tts/ klasÃ¶rÃ¼nÃ¼ Drive'a yÃ¼kleyin: /content/drive/MyDrive/tts/\n",
    "\n",
    "# !cp -r /content/drive/MyDrive/tts /content/\n",
    "# %cd /content/tts\n",
    "# !ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sistem BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± Kur (espeak-ng)\n",
    "\n",
    "TÃ¼rkÃ§e phonemization iÃ§in gerekli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espeak-ng kurulumu\n",
    "!apt-get update -qq\n",
    "!apt-get install -y espeak-ng > /dev/null 2>&1\n",
    "\n",
    "# Kurulum kontrolÃ¼\n",
    "!espeak-ng --version\n",
    "print(\"\\nâœ“ espeak-ng installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± Kur\n\nâš ï¸ **Ã–NEMLI**: PyTorch'u upgrade ETMEYIN! Colab'daki versiyon zaten uyumlu."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# PyTorch zaten Colab'da yÃ¼klÃ¼ - UPGRADE YAPMAYIN!\n# Sadece eksik paketleri yÃ¼kle (sabit versiyonlar)\n\n!pip install -q transformers==4.36.0\n!pip install -q datasets==2.16.0\n!pip install -q peft==0.7.0\n!pip install -q accelerate==0.25.0\n!pip install -q librosa==0.10.1\n!pip install -q soundfile==0.12.1\n!pip install -q scipy==1.11.4\n!pip install -q phonemizer==3.2.1\n!pip install -q sentencepiece==0.1.99\n!pip install -q einops==0.7.0\n!pip install -q matplotlib==3.8.2\n!pip install -q tqdm==4.66.1\n!pip install -q pyyaml==6.0.1\n!pip install -q tensorboard==2.15.1\n!pip install -q torchcodec  # Audio decode iÃ§in gerekli\n\nprint(\"\\nâœ“ All dependencies installed!\")\n\n# Kurulum kontrolÃ¼\nimport torch\nimport transformers\nimport datasets\nimport peft\nimport librosa\nimport phonemizer\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nprint(f\"transformers: {transformers.__version__}\")\nprint(f\"datasets: {datasets.__version__}\")\nprint(f\"peft: {peft.__version__}\")\nprint(f\"librosa: {librosa.__version__}\")\n\n# GPU bilgisi\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    print(f\"\\nğŸ® GPU: {gpu_name}\")\n    if \"V100\" in gpu_name:\n        print(\"âœ“ V100 detected - Using optimized settings (batch_size=16)\")\n    elif \"T4\" in gpu_name:\n        print(\"âœ“ T4 detected - Using standard settings (batch_size=8)\")\n    elif \"A100\" in gpu_name:\n        print(\"âœ“ A100 detected - Using high-performance settings (batch_size=32)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Config DosyasÄ±nÄ± Colab iÃ§in Optimize Et\n\nGPU'ya gÃ¶re otomatik batch size ayarÄ±:\n- **T4**: batch_size=8 (~30-40 saat)\n- **V100**: batch_size=16 (~16-20 saat) âš¡\n- **A100**: batch_size=32 (~8-12 saat) ğŸš€"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import yaml\nimport torch\n\n# Config'i yÃ¼kle\nwith open('config.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\n# GPU ayarlarÄ± (MPS yerine CUDA)\nconfig['training']['device'] = 'cuda'\n\n# GPU'ya gÃ¶re batch size optimize et\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    \n    if \"V100\" in gpu_name:\n        # V100: 2x daha gÃ¼Ã§lÃ¼\n        config['training']['batch_size'] = 16\n        config['training']['gradient_accumulation_steps'] = 2  # Effective: 32\n        print(\"ğŸ® V100 GPU detected - Using batch_size=16\")\n    elif \"A100\" in gpu_name:\n        # A100: 4x daha gÃ¼Ã§lÃ¼\n        config['training']['batch_size'] = 32\n        config['training']['gradient_accumulation_steps'] = 1  # Effective: 32\n        print(\"ğŸ® A100 GPU detected - Using batch_size=32\")\n    else:\n        # T4 veya diÄŸer GPU'lar\n        config['training']['batch_size'] = 8\n        config['training']['gradient_accumulation_steps'] = 4  # Effective: 32\n        print(\"ğŸ® T4 GPU detected - Using batch_size=8\")\nelse:\n    # CPU fallback\n    config['training']['batch_size'] = 2\n    config['training']['gradient_accumulation_steps'] = 16\n\n# Mixed precision (GPU'da daha iyi Ã§alÄ±ÅŸÄ±r)\nconfig['training']['mixed_precision'] = True\nconfig['training']['fp16'] = True\nconfig['training']['bf16'] = False\n\n# Workers (Colab iÃ§in)\nconfig['system']['num_workers'] = 2\nconfig['system']['pin_memory'] = True  # GPU iÃ§in aktif\n\n# Checkpoint'leri Drive'a kaydet\nconfig['training']['checkpoint_dir'] = '/content/drive/MyDrive/tts_checkpoints'\nconfig['training']['tensorboard_dir'] = '/content/drive/MyDrive/tts_runs'\n\n# SÄ±k checkpoint kaydet (disconnect korumasÄ±)\nconfig['training']['save_interval'] = 500  # Her 500 step\nconfig['training']['keep_last_n_checkpoints'] = 5\n\n# Inference output\nconfig['inference']['output_dir'] = '/content/drive/MyDrive/tts_outputs'\n\n# Kaydet\nwith open('config.yaml', 'w') as f:\n    yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n\nprint(\"\\nâœ“ Config updated for Colab GPU!\\n\")\nprint(f\"Device: {config['training']['device']}\")\nprint(f\"Batch size: {config['training']['batch_size']}\")\nprint(f\"Gradient accumulation: {config['training']['gradient_accumulation_steps']}\")\nprint(f\"Effective batch size: {config['training']['batch_size'] * config['training']['gradient_accumulation_steps']}\")\nprint(f\"Mixed precision: {config['training']['mixed_precision']}\")\nprint(f\"Checkpoint dir: {config['training']['checkpoint_dir']}\")\n\n# Tahmini sÃ¼re\ngpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\nif \"V100\" in gpu_name:\n    print(\"\\nâ±ï¸ Estimated training time (100 epochs): ~16-20 hours\")\nelif \"A100\" in gpu_name:\n    print(\"\\nâ±ï¸ Estimated training time (100 epochs): ~8-12 hours\")\nelse:  # T4\n    print(\"\\nâ±ï¸ Estimated training time (100 epochs): ~30-40 hours\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset Test (Otomatik Ä°ndirilir)\n",
    "\n",
    "Ä°lk Ã§alÄ±ÅŸmada dataset Hugging Face'ten indirilir (~1.6GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Dataset'in bir kÄ±smÄ±nÄ± yÃ¼kle (test iÃ§in)\n",
    "print(\"Loading dataset sample...\")\n",
    "dataset_sample = load_dataset(\n",
    "    \"zeynepgulhan/mediaspeech-with-cv-tr\",\n",
    "    split=\"train[:100]\"\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Dataset loaded: {len(dataset_sample)} samples\")\n",
    "print(f\"\\nSample item:\")\n",
    "sample = dataset_sample[0]\n",
    "print(f\"  Text: {sample['sentence']}\")\n",
    "print(f\"  Audio: {len(sample['audio']['array'])} samples @ {sample['audio']['sampling_rate']} Hz\")\n",
    "\n",
    "# Full dataset info\n",
    "full_dataset = load_dataset(\n",
    "    \"zeynepgulhan/mediaspeech-with-cv-tr\",\n",
    "    split=\"train\"\n",
    ")\n",
    "print(f\"\\nFull training dataset: {len(full_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Phonemizer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phonemizer test\n",
    "!python -m src.phonemizer\n",
    "\n",
    "print(\"\\nâœ“ Phonemizer test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Training Test (100 Sample - Debug Mode)\n",
    "\n",
    "Pipeline'Ä±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olmak iÃ§in hÄ±zlÄ± test (~10 dakika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug mode: 100 sample ile test\n",
    "!python -m src.train --config config.yaml --limit-samples 100\n",
    "\n",
    "print(\"\\nâœ“ Quick training test completed!\")\n",
    "print(\"If no errors, you're ready for full training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. TensorBoard (Training Ä°zleme)\n",
    "\n",
    "Training sÄ±rasÄ±nda loss'u canlÄ± takip etmek iÃ§in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard baÅŸlat\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/tts_runs\n",
    "\n",
    "# Training baÅŸladÄ±ktan sonra bu cell'i Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "# Loss grafikleri gÃ¶rÃ¼necek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Session Disconnect KorumasÄ± (Opsiyonel)\n",
    "\n",
    "âš ï¸ Colab Ã¼cretsiz versiyonda ~12 saat sonra disconnect olur. Bu kod bunu engellemeye Ã§alÄ±ÅŸÄ±r (garanti deÄŸil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect korumasÄ± (dikkatli kullanÄ±n)\n",
    "import time\n",
    "from IPython.display import display, Javascript\n",
    "import threading\n",
    "\n",
    "def keep_alive():\n",
    "    \"\"\"Her 5 dakikada bir aktivite simÃ¼le et\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            display(Javascript('document.querySelector(\"colab-toolbar-button#connect\").click()'))\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(300)  # 5 dakika\n",
    "\n",
    "# Background thread olarak Ã§alÄ±ÅŸtÄ±r\n",
    "keep_alive_thread = threading.Thread(target=keep_alive, daemon=True)\n",
    "keep_alive_thread.start()\n",
    "\n",
    "print(\"âœ“ Keep-alive mechanism started\")\n",
    "print(\"âš ï¸ Not guaranteed to prevent all disconnects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. FULL TRAINING (48k Samples)\n",
    "\n",
    "âš ï¸ **DÄ°KKAT**: Bu ~2-3 gÃ¼n sÃ¼recek. Checkpoints Drive'a kaydedilir.\n",
    "\n",
    "**Disconnect olursa**: AÅŸaÄŸÄ±daki \"Resume Training\" hÃ¼cresini kullanÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL TRAINING BAÅLAT\n",
    "!python -m src.train --config config.yaml\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"Best model: /content/drive/MyDrive/tts_checkpoints/best_model.pt\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Resume Training (Disconnect SonrasÄ± Devam)\n",
    "\n",
    "Session disconnect olduysa, en son checkpoint'ten devam edin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En son checkpoint'i bul\n",
    "import glob\n",
    "import os\n",
    "\n",
    "checkpoint_dir = '/content/drive/MyDrive/tts_checkpoints'\n",
    "checkpoints = glob.glob(f'{checkpoint_dir}/checkpoint_step_*.pt')\n",
    "\n",
    "if checkpoints:\n",
    "    # Step numarasÄ±na gÃ¶re sÄ±rala\n",
    "    latest = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    print(f\"Latest checkpoint found: {latest}\")\n",
    "    print(f\"Resuming training...\\n\")\n",
    "    \n",
    "    # Training'e devam et\n",
    "    !python -m src.train --config config.yaml --resume {latest}\n",
    "else:\n",
    "    print(\"No checkpoints found. Start fresh training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Checkpoints Listesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaydedilen tÃ¼m checkpoints\n",
    "!ls -lh /content/drive/MyDrive/tts_checkpoints/\n",
    "\n",
    "# LoRA weights\n",
    "print(\"\\nLoRA adapters:\")\n",
    "!ls -lh /content/drive/MyDrive/tts_checkpoints/lora/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Inference Test (Ses Ãœretimi)\n",
    "\n",
    "Training bittikten sonra modeli test edin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cÃ¼mleleri\n",
    "test_texts = [\n",
    "    \"Merhaba, size nasÄ±l yardÄ±mcÄ± olabilirim?\",\n",
    "    \"BugÃ¼n hava Ã§ok gÃ¼zel.\",\n",
    "    \"TÃ¼rkÃ§e metin seslendirilmesi baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor.\",\n",
    "    \"Bu bir test cÃ¼mlesidir.\",\n",
    "]\n",
    "\n",
    "# Her cÃ¼mle iÃ§in ses Ã¼ret\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"\\nGenerating audio {i+1}/{len(test_texts)}: {text}\")\n",
    "    !python -m src.inference \\\n",
    "        --checkpoint /content/drive/MyDrive/tts_checkpoints/best_model.pt \\\n",
    "        --text \"{text}\"\n",
    "\n",
    "# Ãœretilen dosyalarÄ± Drive'a kopyala\n",
    "!cp outputs/*.wav /content/drive/MyDrive/tts_outputs/\n",
    "\n",
    "print(\"\\nâœ“ Audio files saved to Drive: /content/drive/MyDrive/tts_outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Ses DosyalarÄ±nÄ± Dinle (Colab'da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ãœretilen sesleri Colab'da dinle\n",
    "import IPython.display as ipd\n",
    "import glob\n",
    "\n",
    "audio_files = sorted(glob.glob('/content/drive/MyDrive/tts_outputs/*.wav'))\n",
    "\n",
    "for audio_file in audio_files[-5:]:  # Son 5 dosya\n",
    "    print(f\"\\n{audio_file}\")\n",
    "    display(ipd.Audio(audio_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Training Ä°statistikleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard loglarÄ±ndan training istatistiklerini Ã§ek\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import glob\n",
    "\n",
    "# En son log dosyasÄ±nÄ± bul\n",
    "log_files = glob.glob('/content/drive/MyDrive/tts_runs/events.out.tfevents.*')\n",
    "\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=lambda x: os.path.getmtime(x))\n",
    "    print(f\"Reading log: {latest_log}\\n\")\n",
    "    \n",
    "    ea = event_accumulator.EventAccumulator(latest_log)\n",
    "    ea.Reload()\n",
    "    \n",
    "    # Training loss\n",
    "    if 'train/loss' in ea.Tags()['scalars']:\n",
    "        train_loss = ea.Scalars('train/loss')\n",
    "        print(f\"Total training steps: {len(train_loss)}\")\n",
    "        print(f\"Initial loss: {train_loss[0].value:.4f}\")\n",
    "        print(f\"Final loss: {train_loss[-1].value:.4f}\")\n",
    "    \n",
    "    # Validation loss\n",
    "    if 'val/loss' in ea.Tags()['scalars']:\n",
    "        val_loss = ea.Scalars('val/loss')\n",
    "        print(f\"\\nBest validation loss: {min([x.value for x in val_loss]):.4f}\")\n",
    "else:\n",
    "    print(\"No TensorBoard logs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Model'i Local'e Ä°ndir\n",
    "\n",
    "Training bittikten sonra best model'i bilgisayarÄ±nÄ±za indirin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model ve LoRA weights'i zip'le\n",
    "import shutil\n",
    "\n",
    "output_zip = '/content/drive/MyDrive/turkish_tts_model.zip'\n",
    "\n",
    "# GeÃ§ici dizin oluÅŸtur\n",
    "!mkdir -p /tmp/model_export\n",
    "\n",
    "# Best model ve LoRA weights kopyala\n",
    "!cp /content/drive/MyDrive/tts_checkpoints/best_model.pt /tmp/model_export/\n",
    "!cp -r /content/drive/MyDrive/tts_checkpoints/lora/best_model /tmp/model_export/lora_weights\n",
    "!cp config.yaml /tmp/model_export/\n",
    "!cp data/phoneme_vocab.json /tmp/model_export/\n",
    "\n",
    "# Zip oluÅŸtur\n",
    "shutil.make_archive('/tmp/turkish_tts_model', 'zip', '/tmp/model_export')\n",
    "!mv /tmp/turkish_tts_model.zip {output_zip}\n",
    "\n",
    "print(f\"\\nâœ“ Model exported to: {output_zip}\")\n",
    "print(f\"Download from Google Drive: MyDrive/turkish_tts_model.zip\")\n",
    "print(f\"\\nContents:\")\n",
    "!unzip -l {output_zip}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notlar ve Ä°puÃ§larÄ±\n",
    "\n",
    "### Training SÃ¼reci\n",
    "- **Debug test**: Her zaman Ã¶nce 100 sample ile test edin (hÃ¼cre 9)\n",
    "- **Checkpoint'ler**: Her 500 step'te Drive'a kaydedilir\n",
    "- **TensorBoard**: Training sÄ±rasÄ±nda loss'u izleyin (hÃ¼cre 10)\n",
    "- **Disconnect**: Olursa hÃ¼cre 13 ile devam edin\n",
    "\n",
    "### GPU KullanÄ±mÄ±\n",
    "- **T4 GPU**: Batch size 8 optimal\n",
    "- **V100/A100**: Batch size 16-32'ye Ã§Ä±kabilir\n",
    "- **Out of Memory**: Batch size'Ä± azaltÄ±n (config.yaml)\n",
    "\n",
    "### Sonraki AdÄ±mlar\n",
    "1. Training bitince model'i indirin (hÃ¼cre 18)\n",
    "2. Local'de inference test yapÄ±n\n",
    "3. Ä°sterseniz baÅŸka veri seti ile devam edin\n",
    "\n",
    "### Sorun Giderme\n",
    "- **espeak-ng hatasÄ±**: HÃ¼cre 4'Ã¼ tekrar Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "- **Dataset inmiyor**: Cache temizleyin: `!rm -rf ~/.cache/huggingface`\n",
    "- **CUDA out of memory**: Batch size azaltÄ±n veya High-RAM runtime kullanÄ±n\n",
    "- **Disconnect sÄ±k oluyor**: Colab Pro deneyin (aylÄ±k ~10$)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}