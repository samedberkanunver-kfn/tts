{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish TTS Fine-Tuning on Google Colab\n",
    "\n",
    "Bu notebook, Kokoro-82M modelini Türkçe için fine-tune etmek üzere hazırlanmıştır.\n",
    "\n",
    "**Gereksinimler:**\n",
    "- Runtime: GPU (T4 önerilen)\n",
    "- RAM: High-RAM runtime (opsiyonel ama önerilen)\n",
    "- Google Drive: Checkpoints kaydetmek için\n",
    "\n",
    "**Tahmini Süre:**\n",
    "- Debug (100 sample): ~10 dakika\n",
    "- Full training (48k sample): 2-3 gün (T4 GPU ile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Kontrolü ve Runtime Ayarları\n",
    "\n",
    "⚠️ **ÖNEMLI**: Runtime > Change runtime type > GPU (T4) seçili olmalı!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU kontrolü\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Drive Bağlantısı\n",
    "\n",
    "Checkpoints ve TensorBoard logları Drive'a kaydedilecek (session sonlanırsa kaybolmaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Checkpoint dizinleri oluştur\n",
    "!mkdir -p /content/drive/MyDrive/tts_checkpoints\n",
    "!mkdir -p /content/drive/MyDrive/tts_runs\n",
    "!mkdir -p /content/drive/MyDrive/tts_outputs\n",
    "\n",
    "print(\"\\n✓ Google Drive mounted successfully!\")\n",
    "print(\"  Checkpoints: /content/drive/MyDrive/tts_checkpoints\")\n",
    "print(\"  TensorBoard: /content/drive/MyDrive/tts_runs\")\n",
    "print(\"  Outputs: /content/drive/MyDrive/tts_outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Projeyi GitHub'dan Klonla\n",
    "\n",
    "**Seçenek A**: GitHub kullanıyorsanız (önerilen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub'dan klonla\n",
    "import os\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/samedberkanunver-kfn/tts.git\"  # Buraya kendi repo URL'nizi yazın\n",
    "\n",
    "if os.path.exists('/content/tts'):\n",
    "    print(\"Removing old directory...\")\n",
    "    !rm -rf /content/tts\n",
    "\n",
    "!git clone {GITHUB_REPO} /content/tts\n",
    "%cd /content/tts\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seçenek B**: Google Drive'dan kopyala (GitHub kullanmıyorsanız)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive'dan kopyala (Seçenek B)\n",
    "# Önce tts/ klasörünü Drive'a yükleyin: /content/drive/MyDrive/tts/\n",
    "\n",
    "# !cp -r /content/drive/MyDrive/tts /content/\n",
    "# %cd /content/tts\n",
    "# !ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sistem Bağımlılıklarını Kur (espeak-ng)\n",
    "\n",
    "Türkçe phonemization için gerekli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espeak-ng kurulumu\n",
    "!apt-get update -qq\n",
    "!apt-get install -y espeak-ng > /dev/null 2>&1\n",
    "\n",
    "# Kurulum kontrolü\n",
    "!espeak-ng --version\n",
    "print(\"\\n✓ espeak-ng installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Python Bağımlılıklarını Kur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch zaten Colab'da yüklü, sadece güncelleyelim\n",
    "!pip install -q --upgrade torch torchvision torchaudio\n",
    "\n",
    "# Diğer dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\n✓ All dependencies installed!\")\n",
    "\n",
    "# Kurulum kontrolü\n",
    "import transformers\n",
    "import datasets\n",
    "import peft\n",
    "import librosa\n",
    "import phonemizer\n",
    "\n",
    "print(f\"transformers: {transformers.__version__}\")\n",
    "print(f\"datasets: {datasets.__version__}\")\n",
    "print(f\"peft: {peft.__version__}\")\n",
    "print(f\"librosa: {librosa.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Config Dosyasını Colab için Optimize Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Config'i yükle\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# GPU ayarları (MPS yerine CUDA)\n",
    "config['training']['device'] = 'cuda'\n",
    "\n",
    "# Batch size (T4 GPU için optimize)\n",
    "config['training']['batch_size'] = 8  # M4'te 2, T4'te 8\n",
    "config['training']['gradient_accumulation_steps'] = 4  # Effective batch: 32\n",
    "\n",
    "# Mixed precision (GPU'da daha iyi çalışır)\n",
    "config['training']['mixed_precision'] = True\n",
    "config['training']['fp16'] = True\n",
    "config['training']['bf16'] = False\n",
    "\n",
    "# Workers (Colab için)\n",
    "config['system']['num_workers'] = 2\n",
    "config['system']['pin_memory'] = True  # GPU için aktif\n",
    "\n",
    "# Checkpoint'leri Drive'a kaydet\n",
    "config['training']['checkpoint_dir'] = '/content/drive/MyDrive/tts_checkpoints'\n",
    "config['training']['tensorboard_dir'] = '/content/drive/MyDrive/tts_runs'\n",
    "\n",
    "# Sık checkpoint kaydet (disconnect koruması)\n",
    "config['training']['save_interval'] = 500  # Her 500 step\n",
    "config['training']['keep_last_n_checkpoints'] = 5\n",
    "\n",
    "# Inference output\n",
    "config['inference']['output_dir'] = '/content/drive/MyDrive/tts_outputs'\n",
    "\n",
    "# Kaydet\n",
    "with open('config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(\"✓ Config updated for Colab GPU!\\n\")\n",
    "print(f\"Device: {config['training']['device']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"Gradient accumulation: {config['training']['gradient_accumulation_steps']}\")\n",
    "print(f\"Effective batch size: {config['training']['batch_size'] * config['training']['gradient_accumulation_steps']}\")\n",
    "print(f\"Mixed precision: {config['training']['mixed_precision']}\")\n",
    "print(f\"Checkpoint dir: {config['training']['checkpoint_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset Test (Otomatik İndirilir)\n",
    "\n",
    "İlk çalışmada dataset Hugging Face'ten indirilir (~1.6GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Dataset'in bir kısmını yükle (test için)\n",
    "print(\"Loading dataset sample...\")\n",
    "dataset_sample = load_dataset(\n",
    "    \"zeynepgulhan/mediaspeech-with-cv-tr\",\n",
    "    split=\"train[:100]\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Dataset loaded: {len(dataset_sample)} samples\")\n",
    "print(f\"\\nSample item:\")\n",
    "sample = dataset_sample[0]\n",
    "print(f\"  Text: {sample['sentence']}\")\n",
    "print(f\"  Audio: {len(sample['audio']['array'])} samples @ {sample['audio']['sampling_rate']} Hz\")\n",
    "\n",
    "# Full dataset info\n",
    "full_dataset = load_dataset(\n",
    "    \"zeynepgulhan/mediaspeech-with-cv-tr\",\n",
    "    split=\"train\"\n",
    ")\n",
    "print(f\"\\nFull training dataset: {len(full_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Phonemizer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phonemizer test\n",
    "!python -m src.phonemizer\n",
    "\n",
    "print(\"\\n✓ Phonemizer test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Training Test (100 Sample - Debug Mode)\n",
    "\n",
    "Pipeline'ın çalıştığından emin olmak için hızlı test (~10 dakika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug mode: 100 sample ile test\n",
    "!python -m src.train --config config.yaml --limit-samples 100\n",
    "\n",
    "print(\"\\n✓ Quick training test completed!\")\n",
    "print(\"If no errors, you're ready for full training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. TensorBoard (Training İzleme)\n",
    "\n",
    "Training sırasında loss'u canlı takip etmek için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard başlat\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/tts_runs\n",
    "\n",
    "# Training başladıktan sonra bu cell'i çalıştırın\n",
    "# Loss grafikleri görünecek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Session Disconnect Koruması (Opsiyonel)\n",
    "\n",
    "⚠️ Colab ücretsiz versiyonda ~12 saat sonra disconnect olur. Bu kod bunu engellemeye çalışır (garanti değil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect koruması (dikkatli kullanın)\n",
    "import time\n",
    "from IPython.display import display, Javascript\n",
    "import threading\n",
    "\n",
    "def keep_alive():\n",
    "    \"\"\"Her 5 dakikada bir aktivite simüle et\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            display(Javascript('document.querySelector(\"colab-toolbar-button#connect\").click()'))\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(300)  # 5 dakika\n",
    "\n",
    "# Background thread olarak çalıştır\n",
    "keep_alive_thread = threading.Thread(target=keep_alive, daemon=True)\n",
    "keep_alive_thread.start()\n",
    "\n",
    "print(\"✓ Keep-alive mechanism started\")\n",
    "print(\"⚠️ Not guaranteed to prevent all disconnects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. FULL TRAINING (48k Samples)\n",
    "\n",
    "⚠️ **DİKKAT**: Bu ~2-3 gün sürecek. Checkpoints Drive'a kaydedilir.\n",
    "\n",
    "**Disconnect olursa**: Aşağıdaki \"Resume Training\" hücresini kullanın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL TRAINING BAŞLAT\n",
    "!python -m src.train --config config.yaml\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"Best model: /content/drive/MyDrive/tts_checkpoints/best_model.pt\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Resume Training (Disconnect Sonrası Devam)\n",
    "\n",
    "Session disconnect olduysa, en son checkpoint'ten devam edin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En son checkpoint'i bul\n",
    "import glob\n",
    "import os\n",
    "\n",
    "checkpoint_dir = '/content/drive/MyDrive/tts_checkpoints'\n",
    "checkpoints = glob.glob(f'{checkpoint_dir}/checkpoint_step_*.pt')\n",
    "\n",
    "if checkpoints:\n",
    "    # Step numarasına göre sırala\n",
    "    latest = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    print(f\"Latest checkpoint found: {latest}\")\n",
    "    print(f\"Resuming training...\\n\")\n",
    "    \n",
    "    # Training'e devam et\n",
    "    !python -m src.train --config config.yaml --resume {latest}\n",
    "else:\n",
    "    print(\"No checkpoints found. Start fresh training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Checkpoints Listesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaydedilen tüm checkpoints\n",
    "!ls -lh /content/drive/MyDrive/tts_checkpoints/\n",
    "\n",
    "# LoRA weights\n",
    "print(\"\\nLoRA adapters:\")\n",
    "!ls -lh /content/drive/MyDrive/tts_checkpoints/lora/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Inference Test (Ses Üretimi)\n",
    "\n",
    "Training bittikten sonra modeli test edin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cümleleri\n",
    "test_texts = [\n",
    "    \"Merhaba, size nasıl yardımcı olabilirim?\",\n",
    "    \"Bugün hava çok güzel.\",\n",
    "    \"Türkçe metin seslendirilmesi başarıyla çalışıyor.\",\n",
    "    \"Bu bir test cümlesidir.\",\n",
    "]\n",
    "\n",
    "# Her cümle için ses üret\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"\\nGenerating audio {i+1}/{len(test_texts)}: {text}\")\n",
    "    !python -m src.inference \\\n",
    "        --checkpoint /content/drive/MyDrive/tts_checkpoints/best_model.pt \\\n",
    "        --text \"{text}\"\n",
    "\n",
    "# Üretilen dosyaları Drive'a kopyala\n",
    "!cp outputs/*.wav /content/drive/MyDrive/tts_outputs/\n",
    "\n",
    "print(\"\\n✓ Audio files saved to Drive: /content/drive/MyDrive/tts_outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Ses Dosyalarını Dinle (Colab'da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Üretilen sesleri Colab'da dinle\n",
    "import IPython.display as ipd\n",
    "import glob\n",
    "\n",
    "audio_files = sorted(glob.glob('/content/drive/MyDrive/tts_outputs/*.wav'))\n",
    "\n",
    "for audio_file in audio_files[-5:]:  # Son 5 dosya\n",
    "    print(f\"\\n{audio_file}\")\n",
    "    display(ipd.Audio(audio_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Training İstatistikleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard loglarından training istatistiklerini çek\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import glob\n",
    "\n",
    "# En son log dosyasını bul\n",
    "log_files = glob.glob('/content/drive/MyDrive/tts_runs/events.out.tfevents.*')\n",
    "\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=lambda x: os.path.getmtime(x))\n",
    "    print(f\"Reading log: {latest_log}\\n\")\n",
    "    \n",
    "    ea = event_accumulator.EventAccumulator(latest_log)\n",
    "    ea.Reload()\n",
    "    \n",
    "    # Training loss\n",
    "    if 'train/loss' in ea.Tags()['scalars']:\n",
    "        train_loss = ea.Scalars('train/loss')\n",
    "        print(f\"Total training steps: {len(train_loss)}\")\n",
    "        print(f\"Initial loss: {train_loss[0].value:.4f}\")\n",
    "        print(f\"Final loss: {train_loss[-1].value:.4f}\")\n",
    "    \n",
    "    # Validation loss\n",
    "    if 'val/loss' in ea.Tags()['scalars']:\n",
    "        val_loss = ea.Scalars('val/loss')\n",
    "        print(f\"\\nBest validation loss: {min([x.value for x in val_loss]):.4f}\")\n",
    "else:\n",
    "    print(\"No TensorBoard logs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Model'i Local'e İndir\n",
    "\n",
    "Training bittikten sonra best model'i bilgisayarınıza indirin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model ve LoRA weights'i zip'le\n",
    "import shutil\n",
    "\n",
    "output_zip = '/content/drive/MyDrive/turkish_tts_model.zip'\n",
    "\n",
    "# Geçici dizin oluştur\n",
    "!mkdir -p /tmp/model_export\n",
    "\n",
    "# Best model ve LoRA weights kopyala\n",
    "!cp /content/drive/MyDrive/tts_checkpoints/best_model.pt /tmp/model_export/\n",
    "!cp -r /content/drive/MyDrive/tts_checkpoints/lora/best_model /tmp/model_export/lora_weights\n",
    "!cp config.yaml /tmp/model_export/\n",
    "!cp data/phoneme_vocab.json /tmp/model_export/\n",
    "\n",
    "# Zip oluştur\n",
    "shutil.make_archive('/tmp/turkish_tts_model', 'zip', '/tmp/model_export')\n",
    "!mv /tmp/turkish_tts_model.zip {output_zip}\n",
    "\n",
    "print(f\"\\n✓ Model exported to: {output_zip}\")\n",
    "print(f\"Download from Google Drive: MyDrive/turkish_tts_model.zip\")\n",
    "print(f\"\\nContents:\")\n",
    "!unzip -l {output_zip}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notlar ve İpuçları\n",
    "\n",
    "### Training Süreci\n",
    "- **Debug test**: Her zaman önce 100 sample ile test edin (hücre 9)\n",
    "- **Checkpoint'ler**: Her 500 step'te Drive'a kaydedilir\n",
    "- **TensorBoard**: Training sırasında loss'u izleyin (hücre 10)\n",
    "- **Disconnect**: Olursa hücre 13 ile devam edin\n",
    "\n",
    "### GPU Kullanımı\n",
    "- **T4 GPU**: Batch size 8 optimal\n",
    "- **V100/A100**: Batch size 16-32'ye çıkabilir\n",
    "- **Out of Memory**: Batch size'ı azaltın (config.yaml)\n",
    "\n",
    "### Sonraki Adımlar\n",
    "1. Training bitince model'i indirin (hücre 18)\n",
    "2. Local'de inference test yapın\n",
    "3. İsterseniz başka veri seti ile devam edin\n",
    "\n",
    "### Sorun Giderme\n",
    "- **espeak-ng hatası**: Hücre 4'ü tekrar çalıştırın\n",
    "- **Dataset inmiyor**: Cache temizleyin: `!rm -rf ~/.cache/huggingface`\n",
    "- **CUDA out of memory**: Batch size azaltın veya High-RAM runtime kullanın\n",
    "- **Disconnect sık oluyor**: Colab Pro deneyin (aylık ~10$)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
